package cbs

import (
	"context"
	"fmt"
	"log"

	tccommon "github.com/tencentcloudstack/terraform-provider-tencentcloud/tencentcloud/common"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/resource"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"

	"github.com/tencentcloudstack/terraform-provider-tencentcloud/tencentcloud/internal/helper"
)

func DataSourceTencentCloudCbsStorages() *schema.Resource {
	return &schema.Resource{
		Read: dataSourceTencentCloudCbsStoragesRead,

		Schema: map[string]*schema.Schema{
			"storage_id": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "ID of the CBS to be queried.",
			},
			"storage_name": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "Name of the CBS to be queried.",
			},
			"availability_zone": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "The available zone that the CBS instance locates at.",
			},
			"dedicated_cluster_id": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "Exclusive cluster id.",
			},
			"project_id": {
				Type:        schema.TypeInt,
				Optional:    true,
				Description: "ID of the project with which the CBS is associated.",
			},
			"storage_type": {
				Type:         schema.TypeString,
				Optional:     true,
				ValidateFunc: tccommon.ValidateAllowedStringValue(CBS_STORAGE_TYPE),
				Description:  "Filter by cloud disk media type (`CLOUD_BASIC`: HDD cloud disk | `CLOUD_PREMIUM`: Premium Cloud Storage | `CLOUD_SSD`: SSD cloud disk).",
			},
			"storage_usage": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "Filter by cloud disk type (`SYSTEM_DISK`: system disk | `DATA_DISK`: data disk).",
			},
			"charge_type": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by disk charge type (`POSTPAID_BY_HOUR` | `PREPAID` | `CDCPAID` | `DEDICATED_CLUSTER_PAID`).",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"portable": {
				Type:        schema.TypeBool,
				Optional:    true,
				Description: "Filter by whether the disk is portable (Boolean `true` or `false`).",
			},
			"storage_state": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by disk state (`UNATTACHED` | `ATTACHING` | `ATTACHED` | `DETACHING` | `EXPANDING` | `ROLLBACKING` | `TORECYCLE`).",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"instance_ips": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by attached instance public or private IPs.",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"instance_name": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by attached instance name.",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"tag_keys": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by tag keys.",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"tag_values": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "List filter by tag values.",
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"result_output_file": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: "Used to save results.",
			},
			"storage_list": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: "A list of storage. Each element contains the following attributes:",
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"storage_id": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "ID of CBS.",
						},
						"storage_name": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Name of CBS.",
						},
						"storage_type": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Types of storage medium.",
						},
						"storage_usage": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Types of CBS.",
						},
						"availability_zone": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "The zone of CBS.",
						},
						"dedicated_cluster_id": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Exclusive cluster id.",
						},
						"project_id": {
							Type:        schema.TypeInt,
							Computed:    true,
							Description: "ID of the project.",
						},
						"storage_size": {
							Type:        schema.TypeInt,
							Computed:    true,
							Description: "Volume of CBS.",
						},
						"attached": {
							Type:        schema.TypeBool,
							Computed:    true,
							Description: "Indicates whether the CBS is mounted the CVM.",
						},
						"instance_id": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "ID of the CVM instance that be mounted by this CBS.",
						},
						"encrypt": {
							Type:        schema.TypeBool,
							Computed:    true,
							Description: "Indicates whether CBS is encrypted.",
						},
						"create_time": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Creation time of CBS.",
						},
						"status": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Status of CBS.",
						},
						"tags": {
							Type:        schema.TypeMap,
							Computed:    true,
							Description: "The available tags within this CBS.",
						},
						"prepaid_renew_flag": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "The way that CBS instance will be renew automatically or not when it reach the end of the prepaid tenancy.",
						},
						"charge_type": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: "Pay type of the CBS instance.",
						},
						"throughput_performance": {
							Type:        schema.TypeInt,
							Computed:    true,
							Description: "Add extra performance to the data disk. Only works when disk type is `CLOUD_TSSD` or `CLOUD_HSSD`.",
						},
					},
				},
			},
		},
	}
}

func dataSourceTencentCloudCbsStoragesRead(d *schema.ResourceData, meta interface{}) error {
	defer tccommon.LogElapsed("data_source.tencentcloud_cbs_storages.read")()

	var (
		logId      = tccommon.GetLogId(tccommon.ContextNil)
		ctx        = context.WithValue(context.TODO(), tccommon.LogIdKey, logId)
		cbsService = CbsService{client: meta.(tccommon.ProviderMeta).GetAPIV3Conn()}
	)

	params := make(map[string]interface{})
	if v, ok := d.GetOk("storage_id"); ok {
		params["disk-id"] = v.(string)
	}

	if v, ok := d.GetOk("storage_name"); ok {
		params["disk-name"] = v.(string)
	}

	if v, ok := d.GetOk("availability_zone"); ok {
		params["zone"] = v.(string)
	}

	if v, ok := d.GetOk("dedicated_cluster_id"); ok {
		params["dedicated-cluster-id"] = v.(string)
	}

	if v, ok := d.GetOkExists("project_id"); ok {
		params["project-id"] = fmt.Sprintf("%d", v.(int))
	}

	if v, ok := d.GetOk("storage_type"); ok {
		params["disk-type"] = v.(string)
	}

	if v, ok := d.GetOk("storage_usage"); ok {
		params["disk-usage"] = v.(string)
	}

	if v, ok := d.GetOk("charge_type"); ok {
		params["disk-charge-type"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	if v, ok := d.GetOkExists("portable"); ok {
		if v.(bool) {
			params["portable"] = "TRUE"
		} else {
			params["portable"] = "FALSE"
		}
	}

	if v, ok := d.GetOk("storage_state"); ok {
		params["disk-state"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	if v, ok := d.GetOk("instance_ips"); ok {
		params["instance-ip-address"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	if v, ok := d.GetOk("instance_name"); ok {
		params["instance-name"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	if v, ok := d.GetOk("tag_keys"); ok {
		params["tag-key"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	if v, ok := d.GetOk("tag_values"); ok {
		params["tag-value"] = helper.InterfacesStringsPoint(v.([]interface{}))
	}

	err := resource.Retry(tccommon.ReadRetryTimeout, func() *resource.RetryError {
		storages, e := cbsService.DescribeDisksByFilter(ctx, params)
		if e != nil {
			return tccommon.RetryError(e)
		}

		ids := make([]string, 0, len(storages))
		storageList := make([]map[string]interface{}, 0, len(storages))
		for _, storage := range storages {
			mapping := map[string]interface{}{
				"storage_id":             storage.DiskId,
				"storage_name":           storage.DiskName,
				"storage_usage":          storage.DiskUsage,
				"storage_type":           storage.DiskType,
				"availability_zone":      storage.Placement.Zone,
				"dedicated_cluster_id":   storage.Placement.DedicatedClusterId,
				"project_id":             storage.Placement.ProjectId,
				"storage_size":           storage.DiskSize,
				"attached":               storage.Attached,
				"instance_id":            storage.InstanceId,
				"encrypt":                storage.Encrypt,
				"create_time":            storage.CreateTime,
				"status":                 storage.DiskState,
				"prepaid_renew_flag":     storage.RenewFlag,
				"charge_type":            storage.DiskChargeType,
				"throughput_performance": storage.ThroughputPerformance,
			}

			if storage.Tags != nil {
				tags := make(map[string]interface{}, len(storage.Tags))
				for _, t := range storage.Tags {
					tags[*t.Key] = *t.Value
				}

				mapping["tags"] = tags
			}

			storageList = append(storageList, mapping)
			ids = append(ids, *storage.DiskId)
		}

		d.SetId(helper.DataResourceIdsHash(ids))
		if e = d.Set("storage_list", storageList); e != nil {
			log.Printf("[CRITAL]%s provider set storage list fail, reason:%s\n ", logId, e.Error())
			return resource.NonRetryableError(e)
		}

		output, ok := d.GetOk("result_output_file")
		if ok && output.(string) != "" {
			if e := tccommon.WriteToFile(output.(string), storageList); e != nil {
				return resource.NonRetryableError(e)
			}
		}

		return nil
	})

	if err != nil {
		log.Printf("[CRITAL]%s read cbs storages failed, reason:%s\n ", logId, err.Error())
		return err
	}

	return nil
}
